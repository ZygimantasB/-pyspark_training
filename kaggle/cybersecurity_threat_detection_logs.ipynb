{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-03T07:50:29.570275Z",
     "start_time": "2025-05-03T07:50:29.177754Z"
    }
   },
   "source": [
    "import os\n",
    "import math\n",
    "\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.types import ShortType"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T07:50:33.024528Z",
     "start_time": "2025-05-03T07:50:33.021475Z"
    }
   },
   "cell_type": "code",
   "source": "df_path = \"F:\\Datasets\\CSV datasets\\cybersecurity_threat_detection_logs.csv\"",
   "id": "cae6d8fb69aa73e8",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "os.environ['SPARK_HOME'] = r'C:\\spark\\spark-3.5.5-bin-hadoop3'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = 'jupyter'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON_OPTS'] = 'lab'\n",
    "os.environ['PYSPARK_PYTHON'] = 'python'"
   ],
   "id": "8a5a56b695cfaeb2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName('MOMA art collection - Optimized Local')\n",
    "    .master('local[*]')\n",
    "    .config(\"spark.driver.memory\", \"60g\")\n",
    "    .config(\"spark.driver.maxResultSize\", \"4g\")\n",
    "    .config('spark.sql.adaptive.enabled', 'true')\n",
    "    .config('spark.sql.adaptive.coalescePartitions.enabled', 'true')\n",
    "    .config('spark.sql.adaptive.advisoryPartitionSizeInBytes', '128mb')\n",
    "    .config('spark.sql.shuffle.partitions', '100')\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\")\n",
    "    .config('spark.sql.autoBroadcastJoinThreshold', '256mb')\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "print(f\"SparkSession configured with Driver Memory: {spark.conf.get('spark.driver.memory')}\")"
   ],
   "id": "81a458d42a625001"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = spark.read.option(\n",
    "    \"header\", \"true\"\n",
    ").option(\n",
    "    \"inferSchema\", \"true\"\n",
    ").csv(df_path)"
   ],
   "id": "3fc3065c42075c7b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
